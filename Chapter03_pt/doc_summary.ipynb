{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 문서 요약\n",
    "\n",
    "문서요약은 주어진 문서가 담고 있는 중요한 내용을 요약하여 짧은 텍스트를 생성하는 작업을 말한다.\n",
    "\n",
    "### 문서 요약의 이해\n",
    "문서 요약은 추출 요약(Extractive Summarization)과  생성 요약(Abstractive Summarization)으로 구분된다.\n",
    "추출 요약 : 원본 문서에 있는 주요 문장 혹은 단어를 추출하여 요약문을 작성한다.\n",
    "문장의 중요도를 평가해 순위를 매긴 후, 상위의 문장을 선택한다.\n",
    "전체 입력 텍스트와 코사인 유사도가 높은 문장을 정렬한 후에 상위 문장 2개로 요약문을 만든다.\n",
    "\n",
    "생성 요약 : 원본 문서에 있지 않은 문장이나 단어를 생성해 요약문을 만들기 때문에 추출 요약에 비해 상대적으로 난이도가 높다.\n",
    "원본 텍스트에 대한 이해를 전제로 하여 요약문을 새로 생성하기 때문에 Seq2Seq 모형을 사용한다\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 문서 요약 성능 지표 : ROUGE\n",
    "\n",
    "ROUGE : 모형에 의해 요약된 요약문을 전문가가 요약한 요약문, 즉 정답과 비교하여 성능을 측정한다.\n",
    "단어의 출현 순서와 일치하는 정도를 정밀도과 재현율, F1Score로 측정한다.\n",
    "즉, 전문가가 사용한 단어와 만들어낸 단어가 얼마나 일치하는지 보는 것이다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 데이터셋\n",
    "한국의 경우, AIHub에서 \"요약문 및 레포트 생성 데이터\"라는 추출요약문과 생성요약문을 함께 제공하고 있다.\n",
    "문서 요약을 지원하는 트랜스포머 변형 모형으로 여러가지가 있는데, MBart-50은 한국어 요약을 제공한다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 파이프라인을 이용한 문서 요약"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'model_info' from 'huggingface_hub' (C:\\Users\\ahyeo\\anaconda3\\envs\\TextMining_ver02\\lib\\site-packages\\huggingface_hub\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pipeline\n\u001B[0;32m      2\u001B[0m summarizer \u001B[38;5;241m=\u001B[39m pipeline(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msummarization\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      4\u001B[0m text \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'''\u001B[39m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;124mText mining, text data mining (TDM) or text analytics is the process of deriving high-quality information from text. It involves \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe discovery by computer of new, previously unknown information, by automatically extracting information from different written resources.\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[1] Written resources may include websites, books, emails, reviews, and articles. High-quality information is typically obtained by devising patterns and trends by means such as statistical pattern learning. According to Hotho et al. (2005) we can distinguish between three different perspectives of text mining: information extraction, data mining, and a knowledge discovery in databases (KDD) process.[2] Text mining usually involves the process of structuring the input text (usually parsing, along with the addition of some derived linguistic features and the removal of others, and subsequent insertion into a database), deriving patterns within the structured data, and finally evaluation and interpretation of the output. \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mHigh quality\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m in text mining usually refers to some combination of relevance, novelty, and interest. Typical text mining tasks include text categorization, text clustering, concept/entity extraction, production of granular taxonomies, sentiment analysis, document summarization, and entity relation modeling (i.e., learning relations between named entities).\u001B[39m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;124m'''\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TextMining_ver02\\lib\\site-packages\\transformers\\__init__.py:3026\u001B[0m, in \u001B[0;36m_LazyModule.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   3024\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__version__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   3025\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m __version__\n\u001B[1;32m-> 3026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__getattr__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TextMining_ver02\\lib\\site-packages\\transformers\\file_utils.py:1889\u001B[0m, in \u001B[0;36m_BaseLazyModule.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   1887\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_module(name)\n\u001B[0;32m   1888\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_class_to_module\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[1;32m-> 1889\u001B[0m     module \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_module\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_class_to_module\u001B[49m\u001B[43m[\u001B[49m\u001B[43mname\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1890\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(module, name)\n\u001B[0;32m   1891\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TextMining_ver02\\lib\\site-packages\\transformers\\__init__.py:3020\u001B[0m, in \u001B[0;36m_LazyModule._get_module\u001B[1;34m(self, module_name)\u001B[0m\n\u001B[0;32m   3019\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_module\u001B[39m(\u001B[38;5;28mself\u001B[39m, module_name: \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m-> 3020\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mimportlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m.\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmodule_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__name__\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TextMining_ver02\\lib\\importlib\\__init__.py:127\u001B[0m, in \u001B[0;36mimport_module\u001B[1;34m(name, package)\u001B[0m\n\u001B[0;32m    125\u001B[0m             \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    126\u001B[0m         level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m--> 127\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TextMining_ver02\\lib\\site-packages\\transformers\\pipelines\\__init__.py:21\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpathlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Path\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TYPE_CHECKING, Any, Dict, List, Optional, Tuple, Union\n\u001B[1;32m---> 21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mhuggingface_hub\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m model_info\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconfiguration_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PretrainedConfig\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdynamic_module_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_class_from_dynamic_module\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'model_info' from 'huggingface_hub' (C:\\Users\\ahyeo\\anaconda3\\envs\\TextMining_ver02\\lib\\site-packages\\huggingface_hub\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "summarizer = pipeline(\"summarization\")\n",
    "\n",
    "text = '''\n",
    "Text mining, text data mining (TDM) or text analytics is the process of deriving high-quality information from text. It involves \"the discovery by computer of new, previously unknown information, by automatically extracting information from different written resources.\"[1] Written resources may include websites, books, emails, reviews, and articles. High-quality information is typically obtained by devising patterns and trends by means such as statistical pattern learning. According to Hotho et al. (2005) we can distinguish between three different perspectives of text mining: information extraction, data mining, and a knowledge discovery in databases (KDD) process.[2] Text mining usually involves the process of structuring the input text (usually parsing, along with the addition of some derived linguistic features and the removal of others, and subsequent insertion into a database), deriving patterns within the structured data, and finally evaluation and interpretation of the output. 'High quality' in text mining usually refers to some combination of relevance, novelty, and interest. Typical text mining tasks include text categorization, text clustering, concept/entity extraction, production of granular taxonomies, sentiment analysis, document summarization, and entity relation modeling (i.e., learning relations between named entities).\n",
    "'''\n",
    "\n",
    "result = summarizer(text)\n",
    "print(\"요약문 : \\n\", result)\n",
    "print(\"원문 길이 : \", len(text), \"요약문 길이 :\", len(result[0][\"summaray_text\"]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
